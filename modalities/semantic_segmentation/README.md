# Semantic Segmentation Modality

**AlphaEarth + DINOv3 Fusion for Land Cover Classification**

## ✅ Status: Complete

This modality performs semantic segmentation by fusing two other modalities: AlphaEarth satellite embeddings and DINOv3 aerial imagery features. It uses a custom-trained U-Net model to predict land cover classes for a given area.

## Architecture

This processor acts as a pipeline orchestrator that:
1.  Uses `AlphaEarthProcessor` to get 64-dim satellite embeddings.
2.  Uses `AerialImageryProcessor` to get high-resolution DINOv3 features.
3.  Feeds both into an `AlphaEarthConditionedUNet`, a U-Net model where the AlphaEarth data conditions the processing of the DINOv3 features, likely via cross-attention.
4.  The model predicts a segmentation map (pixel-level land cover classes).
5.  The final output is generated by aggregating these pixel-level maps into H3 hexagons, providing the dominant land cover class and the distribution of all classes within the hexagon.

```
┌───────────────────┐   ┌────────────────────┐
│ AlphaEarth        │   │ Aerial Imagery     │
│ Embeddings (res 10) │   │ DINOv3 (res 10)    │
└─────────┬─────────┘   └──────────┬─────────┘
          │                        │
          ▼                        ▼
┌──────────────────────────────────────────┐
│      AlphaEarth-Conditioned U-Net        │
└───────────────────┬──────────────────────┘
                    │
                    ▼
┌──────────────────────────────────────────┐
│   Pixel-level Semantic Segmentation      │
└───────────────────┬──────────────────────┘
                    │
                    ▼
┌──────────────────────────────────────────┐
│   H3 Aggregation & Class Distribution    │
└──────────────────────────────────────────┘
```

## Features
- Fuses satellite and aerial imagery for enhanced segmentation.
- Uses a custom PyTorch U-Net model with a conditioning mechanism.
- Includes a full training pipeline.
- Outputs both a dominant land cover class and the proportional distribution of all classes for each H3 hexagon.

## Generated Features
- `dominant_class_name`: The most common land cover class in the hexagon (e.g., 'Water', 'Forest', 'Industrial').
- `is_urban`: Boolean indicating if the dominant class is considered urban.
- `class_diversity`: The number of unique land cover classes found in the hexagon.
- `class_*`: A set of columns representing the percentage of each land cover class within the hexagon.

## Example Usage
```python
from modalities.semantic_segmentation import SemanticSegmentationProcessor

# Configuration for the processor
# This processor has a complex config, including sub-configs
# for the model, training, and the child processors.
config = {
    'study_area': 'netherlands',
    'output_dir': 'data/processed/embeddings/semantic_segmentation',
    'model_config': {
        'alphaearth_dim': 64,
        'dinov3_dim': 768,
        'conditioning_dim': 256,
    },
    'training': {
        'epochs': 10, # Example value
        'batch_size': 4,
    },
    # Configs for the processors it depends on
    'alphaearth_config': { 'source_dir': 'path/to/alphaearth_tiffs' },
    'aerial_config': { 'model_name': 'dinov3_rs_base' },
}

# Initialize and run the processor
processor = SemanticSegmentationProcessor(config)
embeddings_path = processor.run_pipeline(
    study_area='netherlands',
    h3_resolution=10,
    output_dir=config['output_dir'],
    queue_gee=False # Assuming data is already downloaded
)

print(f"Semantic segmentation embeddings saved to: {embeddings_path}")
```

## Data Sources
- This processor uses the outputs of `AlphaEarthProcessor` and `AerialImageryProcessor`.
